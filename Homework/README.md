## Info
Данные были взяты с https://www.kaggle.com/datasets/bulter22/airline-data?resource=download . Время вычислений, указанное в zeppelin блокнотах, связаны именно с ними. Но в данном репозитории сохранен лишь отрывок этих данных, полный необходимо скачать с kaggle по ссылке выше. Также все тестировалось в докер среде https://github.com/panovvv/bigdata-docker-compose, которую нужно отдельно установить и после этого поместить туда приведенные блокноты и данные.


## Домашние задания

ДЗ 1

- Подключиться к master-node нашего кластера (IP динамический, укажу перед открытием доступа)
- Найти датасет размером ~50Гб и загрузить в HDFS (к сожалению, сильно больше нельзя - всего на кластере ~430Гб)
- Выполнить задания 2 и 3 из презентации к лекции №1.

ДЗ 2

Обработать датасет из ДЗ 1, используя минимум 3 различных преобразования rdd: map, flatMap, reduceByKey, ... (см. презентацию)

ДЗ 3

1. Собрать виртуальное окружение при помощи Conda, используя хотя бы один пакет, который не является транзитивной зависимостью Spark (к примеру, pandas - является).

2. Запустить код из ДЗ 2 (при необходимости добавьте туда импорт и использование библиотеки, добавленной на шаге 1) на кластере с помощью собранного виртуального окружения, убедившись, что библиотеки оттуда не только корректно импортируются, но и правильно работают.